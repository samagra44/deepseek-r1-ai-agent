# DeepSeek RAG Agent

## Project Overview
      
This is a Retrieval-Augmented Generation (RAG) application built with Streamlit that combines document processing, web search capabilities, and AI-powered question answering. The project uses the DeepSeek model for generating responses and implements a sophisticated RAG system. A powerful Retrieval-Augmented Generation (RAG) application that combines document processing, web search capabilities, and AI-powered question answering.

## Core Components
       
### Main Application ```(app.py)```
    
- Built with Streamlit for the user interface
- Implements a chat interface for user interactions
- Model selection (DeepSeek-R1)
- RAG mode toggle
- Web search fallback option
- Document upload capabilities
- URL ingestion
- Chat history management

## Backend Components
   
### ChromaDB Integration ```(backend/chroma_db.py)```
- Vector database for storing and retrieving document embeddings
- Handles document collection management
- Implements similarity search functionality

## Helper Modules   
   
### PDF Processing ```(helper/pdf_ingestion.py)```
- Handles PDF document parsing and processing
- URL Processing ```(helper/url_ingestion.py)```
- Manages web content ingestion
- Document Chunking ```(helper/split_document_chunks.py)```
- Implements document splitting strategies

## Utility Modules

### RAG Agents ```(utils/rag_agents.py)```
- Implements the RAG pipeline
- Manages context retrieval and response generation
- Web Agents ```(utils/web_agents.py)```
- Handles web search functionality
- Implements web content processing

## Dependencies
- The project relies on several key libraries:
- ```streamlit```: Web application framework
- ```langchain``` and related packages: For LLM integration and RAG implementation
- ```chromadb```: Vector database for document storage
- ```google-generativeai```: Google's AI model integration
- ```duckduckgo-search```: Web search capabilities
- ```beautifulsoup4```: Web scraping
- ```pymupdf```: PDF processing

## ğŸš€ Features
### **ğŸ“„ Document Processing**
- ğŸ“‚ Upload & Process PDFs
- Easily upload PDF documents for processing and retrieval.

- ğŸŒ Ingest Web URLs
- Extract and embed content directly from web pages.

- âœ‚ï¸ Document Chunking & Embedding
- Automatically split documents into chunks and generate vector embeddings.

### **ğŸ§  RAG (Retrieval-Augmented Generation)**
- ğŸ” Context Retrieval
- Fetch relevant context from uploaded documents in real-time.

- ğŸ§­ Similarity-Based Search
- Perform semantic search across document embeddings.

- ğŸ’¬ Context-Aware Responses
- Generate answers grounded in your uploaded content.

### **ğŸŒ Web Search Integration**
- ğŸ†˜ Fallback Web Search
- Automatically switch to web search when documents lack relevant context.

- ğŸ“° Web Content Processing
- Extract meaningful information from web pages.

- ğŸ”— Search Result Integration
- Blend web results seamlessly into chat responses.

### **ğŸ§‘â€ğŸ’» User Interface**
- ğŸ’¬ Clean & Intuitive Chat Interface
- User-friendly design for smooth interactions.

- âš™ï¸ Configuration Sidebar
- Easily adjust settings without leaving the chat.

- ğŸ“¥ Document Upload Interface
- Drag & drop documents directly into the app.

- ğŸ•’ Chat History Management
- Review and manage previous conversations.

### **ğŸ› ï¸ Configuration Options**
- ğŸ¤– Model Selection
- Choose your preferred language model.

- ğŸ” Toggle RAG Mode
- Enable or disable document-based retrieval.

- ğŸŒ Web Search Fallback
- Turn fallback search on or off.

- ğŸ“ Adjust Similarity Threshold
- Fine-tune how closely results should match your query.

## Technical Implementation
    
1. **Document Processing Pipeline**
- Documents are split into chunks
- Chunks are embedded and stored in ChromaDB
- Similarity search is performed for relevant context
      
2. **RAG Pipeline**
- User query is processed
- Relevant context is retrieved from documents
- Context is combined with query for response generation
- Web search fallback if needed
    
3. **Response Generation**
- Uses DeepSeek model for response generation
- Incorporates retrieved context
- Handles both document-based and web-based responses
     
This project represents a sophisticated implementation of RAG technology, combining document processing, web search, and AI-powered question answering in a user-friendly interface.

## Installation

### Prerequisites
- Python 3.8 or higher
- pip (Python package installer)
- Git

### Step 1: Clone the Repository
```bash
git clone https://github.com/samagra44/deepseek-r1-ai-agent.git
cd deepseek-r1-ai-agent
```

### Step 2: Create and Activate Virtual Environment
```bash
# For Windows
python -m venv env
.\env\Scripts\activate

# For macOS/Linux
python -m venv env
source env/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Environment Setup
Create a `.env` file in the root directory with the following variables:
```env
OPENAI_API_KEY=your_openai_api_key
GOOGLE_API_KEY=your_google_api_key
```

### Step 5: Initialize the Database
The application will automatically initialize the ChromaDB database on first run.

## Running the Application

1. Start the Streamlit application:
```bash
streamlit run app.py
```

2. Open your web browser and navigate to:
```
http://localhost:8501
```

## Usage

1. **Upload Documents**
   - Use the sidebar to upload PDF documents
   - Or enter a URL to process web content

2. **Configure Settings**
   - Select model version
   - Toggle RAG mode
   - Enable/disable web search fallback

3. **Start Chatting**
   - Type your questions in the chat input
   - The agent will respond using the uploaded documents and/or web search

## Troubleshooting

### Common Issues

1. **Database Connection Error**
   - Ensure ChromaDB is properly initialized
   - Check if the `chroma_db` directory exists and has proper permissions

2. **API Key Issues**
   - Verify your API keys are correctly set in the `.env` file
   - Ensure the environment variables are properly loaded

3. **Dependency Conflicts**
   - If you encounter dependency conflicts, try:
   ```bash
   pip uninstall -r requirements.txt
   pip install -r requirements.txt
   ```

### Getting Help
If you encounter any issues:
1. Check the error messages in the console
2. Verify all dependencies are correctly installed
3. Ensure your Python version is compatible (3.8+)

## Development

### Project Structure
```
â”œâ”€â”€ app.py                 # Main application file
â”œâ”€â”€ backend/              # Backend components
â”‚   â”œâ”€â”€ chroma_db.py      # Vector database integration
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ helper/               # Helper modules
â”‚   â”œâ”€â”€ pdf_ingestion.py
â”‚   â”œâ”€â”€ url_ingestion.py
â”‚   â””â”€â”€ split_document_chunks.py
â”œâ”€â”€ utils/                # Utility modules
â”‚   â”œâ”€â”€ rag_agents.py
â”‚   â””â”€â”€ web_agents.py
â”œâ”€â”€ tests/                # Test directory
â”œâ”€â”€ config/               # Configuration files
â”œâ”€â”€ requirements.txt      # Project dependencies
â””â”€â”€ README.md            # Project documentation
```

### Running Tests
```bash
python -m pytest tests/
```

## Contributing

1. Fork the repository
2. Create a new branch
3. Make your changes
4. Submit a pull request